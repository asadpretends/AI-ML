{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data = datasets.load_iris()\n",
    "data = read_data.data\n",
    "target = read_data.target\n",
    "data = pandas.DataFrame(data)\n",
    "target = pandas.DataFrame(target)\n",
    "data = pandas.concat([data, target], axis=1)\n",
    "data.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "train = data.sample(frac=0.8, random_state=200)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Convert the data into tensors\n",
    "train_x = torch.from_numpy(train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values).float()\n",
    "train_y = torch.from_numpy(train[['target']].values)\n",
    "test_x = torch.from_numpy(test[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values).float()\n",
    "test_y = torch.from_numpy(test[['target']].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding of the target\n",
    "train_y_one_hot = F.one_hot(train_y.squeeze().long())\n",
    "test_y_one_hot = F.one_hot(test_y.squeeze().long())\n",
    "\n",
    "train_y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4])\n",
      "torch.Size([120, 3])\n",
      "torch.Size([30, 4])\n",
      "torch.Size([30, 3])\n",
      "torch.Size([120, 1])\n",
      "torch.Size([30, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y_one_hot.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y_one_hot.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.1477243900299072\n",
      "Epoch: 100, Loss: 0.7189658880233765\n",
      "Epoch: 200, Loss: 0.5009283423423767\n",
      "Epoch: 300, Loss: 0.40954700112342834\n",
      "Epoch: 400, Loss: 0.3433724045753479\n",
      "Epoch: 500, Loss: 0.276459664106369\n",
      "Epoch: 600, Loss: 0.22301673889160156\n",
      "Epoch: 700, Loss: 0.18154746294021606\n",
      "Epoch: 800, Loss: 0.15184584259986877\n",
      "Epoch: 900, Loss: 0.13108417391777039\n",
      "Epoch: 1000, Loss: 0.11641457676887512\n",
      "Epoch: 1100, Loss: 0.10576408356428146\n",
      "Epoch: 1200, Loss: 0.09778189659118652\n",
      "Epoch: 1300, Loss: 0.09162607043981552\n",
      "Epoch: 1400, Loss: 0.08674764633178711\n",
      "Epoch: 1500, Loss: 0.08279131352901459\n",
      "Epoch: 1600, Loss: 0.07951363921165466\n",
      "Epoch: 1700, Loss: 0.0767444297671318\n",
      "Epoch: 1800, Loss: 0.07436876744031906\n",
      "Epoch: 1900, Loss: 0.0723031610250473\n",
      "Epoch: 2000, Loss: 0.07048555463552475\n",
      "Epoch: 2100, Loss: 0.06887023150920868\n",
      "Epoch: 2200, Loss: 0.06742260605096817\n",
      "Epoch: 2300, Loss: 0.06611540168523788\n",
      "Epoch: 2400, Loss: 0.06492725014686584\n",
      "Epoch: 2500, Loss: 0.06384065002202988\n",
      "Epoch: 2600, Loss: 0.06284180283546448\n",
      "Epoch: 2700, Loss: 0.06191951036453247\n",
      "Epoch: 2800, Loss: 0.06106440722942352\n",
      "Epoch: 2900, Loss: 0.06026846542954445\n",
      "Epoch: 3000, Loss: 0.05952505022287369\n",
      "Epoch: 3100, Loss: 0.058829035609960556\n",
      "Epoch: 3200, Loss: 0.05817488580942154\n",
      "Epoch: 3300, Loss: 0.057558465749025345\n",
      "Epoch: 3400, Loss: 0.056976400315761566\n",
      "Epoch: 3500, Loss: 0.05642584338784218\n",
      "Epoch: 3600, Loss: 0.055904753506183624\n",
      "Epoch: 3700, Loss: 0.05540955439209938\n",
      "Epoch: 3800, Loss: 0.054938722401857376\n",
      "Epoch: 3900, Loss: 0.05448969081044197\n",
      "Epoch: 4000, Loss: 0.054061077535152435\n",
      "Epoch: 4100, Loss: 0.05365123972296715\n",
      "Epoch: 4200, Loss: 0.05325887352228165\n",
      "Epoch: 4300, Loss: 0.052882663905620575\n",
      "Epoch: 4400, Loss: 0.05252138525247574\n",
      "Epoch: 4500, Loss: 0.05217451974749565\n",
      "Epoch: 4600, Loss: 0.05184071138501167\n",
      "Epoch: 4700, Loss: 0.05151950567960739\n",
      "Epoch: 4800, Loss: 0.051209840923547745\n",
      "Epoch: 4900, Loss: 0.05091099441051483\n",
      "Epoch: 5000, Loss: 0.05062248185276985\n",
      "Epoch: 5100, Loss: 0.05034356191754341\n",
      "Epoch: 5200, Loss: 0.05007350817322731\n",
      "Epoch: 5300, Loss: 0.04981199651956558\n",
      "Epoch: 5400, Loss: 0.04955857992172241\n",
      "Epoch: 5500, Loss: 0.04931259527802467\n",
      "Epoch: 5600, Loss: 0.04907369986176491\n",
      "Epoch: 5700, Loss: 0.048841528594493866\n",
      "Epoch: 5800, Loss: 0.04861585050821304\n",
      "Epoch: 5900, Loss: 0.04839612916111946\n",
      "Epoch: 6000, Loss: 0.04818234592676163\n",
      "Epoch: 6100, Loss: 0.047973908483982086\n",
      "Epoch: 6200, Loss: 0.047770582139492035\n",
      "Epoch: 6300, Loss: 0.04757249355316162\n",
      "Epoch: 6400, Loss: 0.04737909138202667\n",
      "Epoch: 6500, Loss: 0.047190163284540176\n",
      "Epoch: 6600, Loss: 0.047005727887153625\n",
      "Epoch: 6700, Loss: 0.04682533070445061\n",
      "Epoch: 6800, Loss: 0.04664880782365799\n",
      "Epoch: 6900, Loss: 0.04647625982761383\n",
      "Epoch: 7000, Loss: 0.046307213604450226\n",
      "Epoch: 7100, Loss: 0.04614190757274628\n",
      "Epoch: 7200, Loss: 0.045979730784893036\n",
      "Epoch: 7300, Loss: 0.04582088440656662\n",
      "Epoch: 7400, Loss: 0.04566514492034912\n",
      "Epoch: 7500, Loss: 0.045512523502111435\n",
      "Epoch: 7600, Loss: 0.04536282643675804\n",
      "Epoch: 7700, Loss: 0.04521589353680611\n",
      "Epoch: 7800, Loss: 0.04507163539528847\n",
      "Epoch: 7900, Loss: 0.044929880648851395\n",
      "Epoch: 8000, Loss: 0.044790659099817276\n",
      "Epoch: 8100, Loss: 0.044653989374637604\n",
      "Epoch: 8200, Loss: 0.04451978951692581\n",
      "Epoch: 8300, Loss: 0.04438760131597519\n",
      "Epoch: 8400, Loss: 0.044257961213588715\n",
      "Epoch: 8500, Loss: 0.0441301204264164\n",
      "Epoch: 8600, Loss: 0.04400463402271271\n",
      "Epoch: 8700, Loss: 0.043881092220544815\n",
      "Epoch: 8800, Loss: 0.043759699910879135\n",
      "Epoch: 8900, Loss: 0.04364006221294403\n",
      "Epoch: 9000, Loss: 0.04352199286222458\n",
      "Epoch: 9100, Loss: 0.04340623319149017\n",
      "Epoch: 9200, Loss: 0.04329190403223038\n",
      "Epoch: 9300, Loss: 0.04317938908934593\n",
      "Epoch: 9400, Loss: 0.04306871443986893\n",
      "Epoch: 9500, Loss: 0.042959775775671005\n",
      "Epoch: 9600, Loss: 0.04285251721739769\n",
      "Epoch: 9700, Loss: 0.04274642467498779\n",
      "Epoch: 9800, Loss: 0.04264194145798683\n",
      "Epoch: 9900, Loss: 0.04253900796175003\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "newt = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(newt.parameters(), lr=0.01)\n",
    "losses = []\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = newt(train_x)\n",
    "    train_y_one_hot = train_y_one_hot.float()\n",
    "    loss = criterion(out, train_y_one_hot)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4])\n",
      "torch.Size([120, 3])\n",
      "torch.Size([30, 4])\n",
      "torch.Size([30, 3])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1,\n",
      "        2, 2, 2, 2, 2, 2])\n",
      "Actual:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2], dtype=torch.int32)\n",
      "Accuracy of the network on the 30 test images: 80 %\n"
     ]
    }
   ],
   "source": [
    "# Predict the test data\n",
    "out = newt(test_x)\n",
    "_, predicted = torch.max(out.data, 1)\n",
    "print('Predicted: ', predicted)\n",
    "print('Actual: ', test_y.squeeze())\n",
    "\n",
    "# Calculate the accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "        out = newt(test_x)\n",
    "        _, predicted = torch.max(out.data, 0)\n",
    "        total += test_y.size(0)\n",
    "        correct += (predicted == test_y).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 30 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ce2397aef71c0d12f785fd87c0b7fef94ead8d2f4d1a9ae094c6557efed0fcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
