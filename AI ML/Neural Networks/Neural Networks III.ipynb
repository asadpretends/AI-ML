{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9444878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset,Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from __main__ import SimplePreprocessor\n",
    "# from __main__ import SimpleDatasetLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aac30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c93f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDatasetLoader:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, preprocessors=None):\n",
    "        \"\"\"\n",
    "        :param preprocessors: List of image preprocessors\n",
    "        \"\"\"\n",
    "        self.preprocessors = preprocessors\n",
    "\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "\n",
    "    # Method: Used to load a list of images for pre-processing\n",
    "    def load(self, image_paths, verbose=-1):\n",
    "        \"\"\"\n",
    "        :param image_paths: List of image paths\n",
    "        :param verbose: Parameter for printing information to console\n",
    "        :return: Tuple of data and labels\n",
    "        \"\"\"\n",
    "        data, labels = [], []\n",
    "\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            image = cv2.imread(image_path)\n",
    "            label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "            if self.preprocessors is not None:\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
    "                print('[INFO]: Processed {}/{}'.format(i+1, len(image_paths)))\n",
    "        return (np.array(data), np.array(labels))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068a440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Images loading....\n",
      "[INFO]: Processed 500/3000\n",
      "[INFO]: Processed 1000/3000\n",
      "[INFO]: Processed 1500/3000\n",
      "[INFO]: Processed 2000/3000\n",
      "[INFO]: Processed 2500/3000\n",
      "[INFO]: Processed 3000/3000\n",
      "(2250, 3072)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SimplePreprocessor:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, width, height, interpolation=cv2.INTER_AREA):\n",
    "        \"\"\"\n",
    "        :param width: Image width\n",
    "        :param height: Image height\n",
    "        :param interpolation: Interpolation algorithm\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    # Method: Used to resize the image to a fixed size (ignoring the aspect ratio)\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"\n",
    "        :param image: Image\n",
    "        :return: Re-sized image\n",
    "        \"\"\"\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.interpolation)\n",
    "\n",
    "\n",
    "image_paths = list(paths.list_images(\"animals\"))\n",
    "\n",
    "# Initialize SimplePreprocessor and SimpleDatasetLoader and load data and labels\n",
    "print('[INFO]: Images loading....')\n",
    "sp = SimplePreprocessor(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(image_paths, verbose=500)\n",
    "\n",
    "# Reshape from (3000, 32, 32, 3) to (3000, 32*32*3=3072)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# Print information about memory consumption\n",
    "# print('[INFO]: Features Matrix: {:.1f}MB'.format(float(data.nbytes / 1024*1000.0)))\n",
    "\n",
    "# Encode labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Split data into training (75%) and testing (25%) data\n",
    "X_train, X_test, y_train, y_test= train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ab1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class class_dataset(Dataset):\n",
    "    def __init__(self,x_tensor,y_tensor):\n",
    "        super().__init__()\n",
    "        self.X = x_tensor\n",
    "        self.Y = y_tensor\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        return (self.X[i],self.Y[i])\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "class SimpleClassificationNet(torch.nn.Module):\n",
    "            \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.linearLayer1 = nn.Linear(3072,1536)\n",
    "        self.s1 = nn.ReLU()\n",
    "        self.linearLayer2 = nn.Linear(1536,200)\n",
    "        self.s2 = nn.ReLU()\n",
    "        self.linearLayer3 = nn.Linear(200,3)\n",
    "        self.s3 = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        first = self.linearLayer1(x)\n",
    "        v = self.s1(first)\n",
    "        second = self.linearLayer2(v)\n",
    "        x = self.s2(second)\n",
    "        y_hat = self.linearLayer3(x)\n",
    "        return y_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60091b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[315 290 133]\n",
      " [286 316 149]\n",
      " [138 154 469]]\n",
      "epoch= 0, accuracyTrain= 0.4888888888888889, accuracyVal= 0.5493333333333333, train_loss= 5.239010468986299, validation_loss= 0.8658189725875854\n",
      "[[382 273  83]\n",
      " [299 335 117]\n",
      " [ 76 137 548]]\n",
      "epoch= 1, accuracyTrain= 0.5622222222222222, accuracyVal= 0.5573333333333333, train_loss= 0.8543066169155968, validation_loss= 0.8635388024648031\n",
      "[[392 279  67]\n",
      " [270 390  91]\n",
      " [ 76 105 580]]\n",
      "epoch= 2, accuracyTrain= 0.6053333333333333, accuracyVal= 0.6093333333333333, train_loss= 0.805726036230723, validation_loss= 0.7744436275959015\n",
      "[[409 261  68]\n",
      " [266 391  94]\n",
      " [ 65  98 598]]\n",
      "epoch= 3, accuracyTrain= 0.6213333333333333, accuracyVal= 0.5746666666666667, train_loss= 0.7572512177626292, validation_loss= 0.8353607126077016\n",
      "[[431 244  63]\n",
      " [253 400  98]\n",
      " [ 52  92 617]]\n",
      "epoch= 4, accuracyTrain= 0.6435555555555555, accuracyVal= 0.592, train_loss= 0.7275443626774682, validation_loss= 0.802491182088852\n",
      "[[443 246  49]\n",
      " [265 402  84]\n",
      " [ 47  84 630]]\n",
      "epoch= 5, accuracyTrain= 0.6555555555555556, accuracyVal= 0.5986666666666667, train_loss= 0.7005731856822968, validation_loss= 0.7953336274623871\n",
      "[[457 238  43]\n",
      " [263 400  88]\n",
      " [ 43  72 646]]\n",
      "epoch= 6, accuracyTrain= 0.668, accuracyVal= 0.588, train_loss= 0.6753168035215802, validation_loss= 0.8120257476965587\n",
      "[[455 237  46]\n",
      " [240 426  85]\n",
      " [ 23  81 657]]\n",
      "epoch= 7, accuracyTrain= 0.6835555555555556, accuracyVal= 0.596, train_loss= 0.6418792479568057, validation_loss= 0.8036380819479625\n",
      "[[444 247  47]\n",
      " [222 457  72]\n",
      " [ 40  57 664]]\n",
      "epoch= 8, accuracyTrain= 0.6955555555555556, accuracyVal= 0.584, train_loss= 0.6305062996678882, validation_loss= 0.7967766535282135\n",
      "[[484 220  34]\n",
      " [204 477  70]\n",
      " [ 31  61 669]]\n",
      "epoch= 9, accuracyTrain= 0.7244444444444444, accuracyVal= 0.584, train_loss= 0.5908530176348157, validation_loss= 0.8204013446966807\n",
      "[[477 224  37]\n",
      " [221 473  57]\n",
      " [ 23  58 680]]\n",
      "epoch= 10, accuracyTrain= 0.7244444444444444, accuracyVal= 0.576, train_loss= 0.573242455455992, validation_loss= 0.926172692378362\n",
      "[[478 224  36]\n",
      " [194 502  55]\n",
      " [ 30  48 683]]\n",
      "epoch= 11, accuracyTrain= 0.7391111111111112, accuracyVal= 0.5813333333333334, train_loss= 0.555007889005873, validation_loss= 0.9236412612597148\n",
      "[[489 219  30]\n",
      " [221 473  57]\n",
      " [ 26  53 682]]\n",
      "epoch= 12, accuracyTrain= 0.7306666666666667, accuracyVal= 0.5893333333333334, train_loss= 0.5664070455233255, validation_loss= 0.8624121179183324\n",
      "[[505 213  20]\n",
      " [205 511  35]\n",
      " [ 14  48 699]]\n",
      "epoch= 13, accuracyTrain= 0.7622222222222222, accuracyVal= 0.6053333333333333, train_loss= 0.5082855769660738, validation_loss= 0.9109471203883489\n",
      "[[486 217  35]\n",
      " [174 525  52]\n",
      " [ 16  53 692]]\n",
      "epoch= 14, accuracyTrain= 0.7568888888888889, accuracyVal= 0.5866666666666667, train_loss= 0.5102349378665288, validation_loss= 0.9749016427993774\n",
      "[[520 200  18]\n",
      " [185 521  45]\n",
      " [ 14  44 703]]\n",
      "epoch= 15, accuracyTrain= 0.7751111111111111, accuracyVal= 0.604, train_loss= 0.46635449720753563, validation_loss= 0.8564928650856019\n",
      "[[530 190  18]\n",
      " [182 534  35]\n",
      " [ 12  30 719]]\n",
      "epoch= 16, accuracyTrain= 0.7924444444444444, accuracyVal= 0.576, train_loss= 0.4400338677565257, validation_loss= 0.9568503050009409\n",
      "[[537 182  19]\n",
      " [191 523  37]\n",
      " [ 15  36 710]]\n",
      "epoch= 17, accuracyTrain= 0.7866666666666666, accuracyVal= 0.5973333333333334, train_loss= 0.4623795589639081, validation_loss= 0.9286746533711752\n",
      "[[516 205  17]\n",
      " [171 543  37]\n",
      " [ 15  36 710]]\n",
      "epoch= 18, accuracyTrain= 0.7862222222222223, accuracyVal= 0.5973333333333334, train_loss= 0.4609400673707326, validation_loss= 0.9735365535815557\n",
      "[[521 198  19]\n",
      " [164 543  44]\n",
      " [ 17  38 706]]\n",
      "epoch= 19, accuracyTrain= 0.7866666666666666, accuracyVal= 0.604, train_loss= 0.456797166566054, validation_loss= 0.9172613863150278\n",
      "[[539 176  23]\n",
      " [163 558  30]\n",
      " [ 13  39 709]]\n",
      "epoch= 20, accuracyTrain= 0.8026666666666666, accuracyVal= 0.596, train_loss= 0.4262738408313857, validation_loss= 1.1323287934064865\n",
      "[[557 166  15]\n",
      " [161 569  21]\n",
      " [ 15  28 718]]\n",
      "epoch= 21, accuracyTrain= 0.8195555555555556, accuracyVal= 0.5866666666666667, train_loss= 0.39164385186301337, validation_loss= 0.8813408082723617\n",
      "[[562 165  11]\n",
      " [136 594  21]\n",
      " [ 10  23 728]]\n",
      "epoch= 22, accuracyTrain= 0.8373333333333334, accuracyVal= 0.6, train_loss= 0.35935258431567085, validation_loss= 0.9896118772029877\n",
      "[[579 150   9]\n",
      " [143 581  27]\n",
      " [ 10  23 728]]\n",
      "epoch= 23, accuracyTrain= 0.8391111111111111, accuracyVal= 0.6053333333333333, train_loss= 0.36741308932503064, validation_loss= 0.9854967401425043\n",
      "[[578 149  11]\n",
      " [138 593  20]\n",
      " [ 13  18 730]]\n",
      "epoch= 24, accuracyTrain= 0.8448888888888889, accuracyVal= 0.5986666666666667, train_loss= 0.3467373420132531, validation_loss= 1.085407641430696\n",
      "[[582 145  11]\n",
      " [144 578  29]\n",
      " [ 12  29 720]]\n",
      "epoch= 25, accuracyTrain= 0.8355555555555556, accuracyVal= 0.612, train_loss= 0.34559270742866727, validation_loss= 0.9936226405700048\n",
      "[[583 142  13]\n",
      " [136 591  24]\n",
      " [ 12  24 725]]\n",
      "epoch= 26, accuracyTrain= 0.844, accuracyVal= 0.6266666666666667, train_loss= 0.366582198018829, validation_loss= 1.0975537909070652\n",
      "[[592 132  14]\n",
      " [132 599  20]\n",
      " [ 13  27 721]]\n",
      "epoch= 27, accuracyTrain= 0.8497777777777777, accuracyVal= 0.58, train_loss= 0.35378820547627077, validation_loss= 1.2529444559415182\n",
      "[[597 131  10]\n",
      " [121 607  23]\n",
      " [  5  27 729]]\n",
      "epoch= 28, accuracyTrain= 0.8591111111111112, accuracyVal= 0.5813333333333334, train_loss= 0.32496409540375076, validation_loss= 1.294626313050588\n",
      "[[582 148   8]\n",
      " [139 589  23]\n",
      " [ 12  22 727]]\n",
      "epoch= 29, accuracyTrain= 0.8435555555555555, accuracyVal= 0.596, train_loss= 0.3388322571251127, validation_loss= 1.100562283595403\n",
      "[[582 144  12]\n",
      " [131 596  24]\n",
      " [ 10  18 733]]\n",
      "epoch= 30, accuracyTrain= 0.8493333333333334, accuracyVal= 0.6013333333333334, train_loss= 0.3456873642736011, validation_loss= 1.138997164964676\n",
      "[[617 114   7]\n",
      " [103 633  15]\n",
      " [  2  17 742]]\n",
      "epoch= 31, accuracyTrain= 0.8853333333333333, accuracyVal= 0.6133333333333333, train_loss= 0.2532589950107245, validation_loss= 1.1069605207443238\n",
      "[[631 101   6]\n",
      " [ 97 645   9]\n",
      " [  6  10 745]]\n",
      "epoch= 32, accuracyTrain= 0.8982222222222223, accuracyVal= 0.6013333333333334, train_loss= 0.24258814534379378, validation_loss= 1.1593462439378102\n",
      "[[625 104   9]\n",
      " [108 629  14]\n",
      " [  2  23 736]]\n",
      "epoch= 33, accuracyTrain= 0.8844444444444445, accuracyVal= 0.596, train_loss= 0.27998358973612386, validation_loss= 1.3642326919237773\n",
      "[[629 106   3]\n",
      " [ 84 660   7]\n",
      " [  1   6 754]]\n",
      "epoch= 34, accuracyTrain= 0.908, accuracyVal= 0.62, train_loss= 0.2085817652112908, validation_loss= 1.273167932232221\n",
      "[[607 117  14]\n",
      " [ 91 635  25]\n",
      " [ 12  25 724]]\n",
      "epoch= 35, accuracyTrain= 0.8737777777777778, accuracyVal= 0.5986666666666667, train_loss= 0.29825793490331204, validation_loss= 1.2959204906225203\n",
      "[[635  93  10]\n",
      " [ 99 640  12]\n",
      " [ 10  14 737]]\n",
      "epoch= 36, accuracyTrain= 0.8942222222222223, accuracyVal= 0.5706666666666667, train_loss= 0.25148743987083433, validation_loss= 1.4881534069776534\n",
      "[[644  91   3]\n",
      " [ 74 672   5]\n",
      " [  2  12 747]]\n",
      "epoch= 37, accuracyTrain= 0.9168888888888889, accuracyVal= 0.5973333333333334, train_loss= 0.20790018069557845, validation_loss= 1.2925325206915537\n",
      "[[641  88   9]\n",
      " [ 93 639  19]\n",
      " [  5  22 734]]\n",
      "epoch= 38, accuracyTrain= 0.8951111111111111, accuracyVal= 0.6053333333333333, train_loss= 0.25640241800496977, validation_loss= 1.4093172955513\n",
      "[[630  95  13]\n",
      " [ 81 661   9]\n",
      " [  9  14 738]]\n",
      "epoch= 39, accuracyTrain= 0.9017777777777778, accuracyVal= 0.612, train_loss= 0.25770046793338325, validation_loss= 1.27841373026371\n",
      "[[652  86   0]\n",
      " [ 78 666   7]\n",
      " [  4   8 749]]\n",
      "epoch= 40, accuracyTrain= 0.9186666666666666, accuracyVal= 0.616, train_loss= 0.18414557453658845, validation_loss= 1.4126727106173833\n",
      "[[635  93  10]\n",
      " [ 80 654  17]\n",
      " [ 12  18 731]]\n",
      "epoch= 41, accuracyTrain= 0.8977777777777778, accuracyVal= 0.6186666666666667, train_loss= 0.257438900458316, validation_loss= 1.4853928339481355\n",
      "[[648  82   8]\n",
      " [ 81 664   6]\n",
      " [  2   7 752]]\n",
      "epoch= 42, accuracyTrain= 0.9173333333333333, accuracyVal= 0.6066666666666667, train_loss= 0.20835553493454226, validation_loss= 1.3080840921401977\n",
      "[[660  72   6]\n",
      " [ 66 678   7]\n",
      " [  7  10 744]]\n",
      "epoch= 43, accuracyTrain= 0.9253333333333333, accuracyVal= 0.5786666666666667, train_loss= 0.17961587723758485, validation_loss= 1.4906602994600933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[659  70   9]\n",
      " [ 77 660  14]\n",
      " [  4  22 735]]\n",
      "epoch= 44, accuracyTrain= 0.9128888888888889, accuracyVal= 0.592, train_loss= 0.24295649013171594, validation_loss= 1.4919495075941085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Preparing PyTorch DataSets and DataLoaders\n",
    "\n",
    "# Builds tensors from numpy arrays\n",
    "\n",
    "x_train_t = torch.as_tensor(X_train).float()\n",
    "y_train_t = torch.as_tensor(y_train).long()\n",
    "x_val_t = torch.as_tensor(X_test).float()\n",
    "y_val_t = torch.as_tensor(y_test).long()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "\n",
    "train_dataset = class_dataset(x_train_t,y_train_t)\n",
    "val_dataset = class_dataset(x_val_t,y_val_t)\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_load = DataLoader(dataset= train_dataset, batch_size = 10, shuffle = True)\n",
    "val_load = DataLoader(dataset = val_dataset,batch_size = 10)\n",
    "\n",
    "#model, optimizer and loss\n",
    "model = SimpleClassificationNet().to(device)\n",
    "stateDict=model.state_dict()\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "#  define optimizor here\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "# define loss here\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#batch wise training loop\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_accuracy=0\n",
    "for epoch in range(epochs):  #epochs loop\n",
    "\n",
    "    all_Y_train_epoch=np.array([]).reshape(0,1)\n",
    "    all_Yhat_train_epoch=np.array([]).reshape(0,1)\n",
    "    all_train_losses_epoch=np.array([])\n",
    "\n",
    "    for X_train, Y_train in train_load:        #batch wise  training on train set\n",
    "        model.train()\n",
    "        X_train = X_train.to(device)\n",
    "        Y_train = Y_train.to(device)\n",
    "        logits = model(X_train)\n",
    "\n",
    "        loss = loss_function(logits,Y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    \n",
    "#     backward passs\n",
    "        \n",
    "        #store metrics for all batches of current epoch \n",
    "        y_hat=F.softmax(logits,dim=-1)\n",
    "        y_hat=y_hat.detach().cpu().numpy()\n",
    "        y_hat=np.argmax(y_hat,axis=1)\n",
    "        y_hat=y_hat.reshape(-1,1)\n",
    "\n",
    "        Y_train=Y_train.detach().cpu().numpy()\n",
    "        Y_train=Y_train.reshape(-1,1)\n",
    "        all_Y_train_epoch=np.vstack((all_Y_train_epoch,Y_train))\n",
    "        all_Yhat_train_epoch=np.vstack((all_Yhat_train_epoch,y_hat))   \n",
    "        all_train_losses_epoch=np.append(all_train_losses_epoch,loss.item())     \n",
    "        \n",
    "    \n",
    "    \n",
    "    #computing metrics for current epoch\n",
    "    train_losses.append(all_train_losses_epoch.mean()) #mean loss for all batches    \n",
    "    acTrain=accuracy_score(all_Y_train_epoch, all_Yhat_train_epoch)\n",
    "    cmTrain=confusion_matrix(all_Y_train_epoch, all_Yhat_train_epoch)\n",
    "    print(cmTrain)\n",
    "\n",
    "    #validation loop also bacth wise\n",
    "    all_Y_val_epoch=np.array([]).reshape(0,1)\n",
    "    all_Yhat_val_epoch=np.array([]).reshape(0,1)\n",
    "    all_val_losses_epoch=np.array([])\n",
    "    for X_val, Y_val in val_load:  #batch wise validation set predictions only\n",
    "        model.eval()\n",
    "        \n",
    "        X_val = X_val.to(device)\n",
    "        Y_val = Y_val.to(device)\n",
    "        \n",
    "        with torch.no_grad():            \n",
    "            logits = model(X_val)           \n",
    "            loss = loss_function(logits, Y_val)\n",
    "        \n",
    "        #store metrics for all batches of current epoch \n",
    "        y_hat_val=F.softmax(logits,dim=-1)\n",
    "        y_hat_val=y_hat_val.detach().cpu().numpy()\n",
    "        y_hat_val=np.argmax(y_hat_val,axis=1)\n",
    "        y_hat_val=y_hat_val.reshape(-1,1)\n",
    "        Y_val=Y_val.detach().cpu().numpy()\n",
    "        Y_val=Y_val.reshape(-1,1)\n",
    "        all_Y_val_epoch=np.vstack((all_Y_val_epoch,Y_val))\n",
    "        all_Yhat_val_epoch=np.vstack((all_Yhat_val_epoch,y_hat_val))   \n",
    "        all_val_losses_epoch=np.append(all_val_losses_epoch,loss.item())     \n",
    "            \n",
    "\n",
    "    #computing metrics for current epoch\n",
    "    val_losses.append(all_val_losses_epoch.mean()) #mean loss for all batches    \n",
    "    acVal=accuracy_score(all_Y_val_epoch, all_Yhat_val_epoch)\n",
    "    cmVal=confusion_matrix(all_Y_val_epoch, all_Yhat_val_epoch)\n",
    "    \n",
    "    print(f\"epoch= {epoch}, accuracyTrain= {acTrain}, accuracyVal= {acVal}, train_loss= {train_losses[epoch]}, validation_loss= {val_losses[epoch]}\")\n",
    "    \n",
    "    #checkpointing training\n",
    "    if(acVal>best_accuracy):\n",
    "        checkpoint = {'epoch': epoch,'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),'loss': train_losses,\n",
    "                      'val_loss': val_losses}\n",
    "        torch.save(checkpoint,'best.pth')\n",
    "\n",
    "\n",
    "\n",
    "#loading best model\n",
    "checkpoint = torch.load('best.pth')\n",
    "# Restore state for model and optimizer\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "total_epochs = checkpoint['epoch']\n",
    "losses = checkpoint['loss']\n",
    "val_losses = checkpoint['val_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
