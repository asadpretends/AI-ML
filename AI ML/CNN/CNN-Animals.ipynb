{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b56b4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset,Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "#Class to load the dataset images from drivce\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8564b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "839276bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # for updation of weights in a batch.\n",
    "num_classes = 3  # Number of class for the dataset\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df6f93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleDatasetLoader:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, preprocessors=None):\n",
    "        \"\"\"\n",
    "        :param preprocessors: List of image preprocessors\n",
    "        \"\"\"\n",
    "        self.preprocessors = preprocessors\n",
    "\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "\n",
    "    # Method: Used to load a list of images for pre-processing\n",
    "    def load(self, image_paths, verbose=-1):\n",
    "        \"\"\"\n",
    "        :param image_paths: List of image paths\n",
    "        :param verbose: Parameter for printing information to console\n",
    "        :return: Tuple of data and labels\n",
    "        \"\"\"\n",
    "        data, labels = [], []\n",
    "\n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            image = cv2.imread(image_path)\n",
    "            label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "            if self.preprocessors is not None:\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "            if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
    "                print('[INFO]: Processed {}/{}'.format(i+1, len(image_paths)))\n",
    "\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9cff1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Preprocessror \n",
    "class SimplePreprocessor:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, width, height, interpolation=cv2.INTER_AREA):\n",
    "        \"\"\"\n",
    "        :param width: Image width\n",
    "        :param height: Image height\n",
    "        :param interpolation: Interpolation algorithm\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    # Method: Used to resize the image to a fixed size (ignoring the aspect ratio)\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"\n",
    "        :param image: Image\n",
    "        :return: Re-sized image\n",
    "        \"\"\"\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b0694ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Preprocessror \n",
    "class SimplePreprocessor:\n",
    "    # Method: Constructor\n",
    "    def __init__(self, width, height, interpolation=cv2.INTER_AREA):\n",
    "        \"\"\"\n",
    "        :param width: Image width\n",
    "        :param height: Image height\n",
    "        :param interpolation: Interpolation algorithm\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    # Method: Used to resize the image to a fixed size (ignoring the aspect ratio)\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"\n",
    "        :param image: Image\n",
    "        :return: Re-sized image\n",
    "        \"\"\"\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8405c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Images loading....\n",
      "[INFO]: Processed 500/3000\n",
      "[INFO]: Processed 1000/3000\n",
      "[INFO]: Processed 1500/3000\n",
      "[INFO]: Processed 2000/3000\n",
      "[INFO]: Processed 2500/3000\n",
      "[INFO]: Processed 3000/3000\n",
      "(3000, 3072)\n"
     ]
    }
   ],
   "source": [
    "image_paths = list(paths.list_images(\"animals\"))\n",
    "\n",
    "# Initialize SimplePreprocessor and SimpleDatasetLoader and load data and labels\n",
    "print('[INFO]: Images loading....')\n",
    "sp = SimplePreprocessor(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(image_paths, verbose=500)\n",
    "\n",
    "# Reshape from (3000, 32, 32, 3) to (3000, 32*32*3=3072)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "print(data.shape)\n",
    "# Print information about memory consumption\n",
    "# print('[INFO]: Features Matrix: {:.1f}MB'.format(float(data.nbytes / 1024*1000.0)))\n",
    "\n",
    "# Encode labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "# Split data into training (75%) and testing (25%) data\n",
    "X_train, X_test, y_train, y_test= train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1a71778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 3072)\n",
      "-------------\n",
      "(750, 3072)\n",
      "--------------\n",
      "(2250,)\n",
      "--------------\n",
      "(750,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print('-------------')\n",
    "print(X_test.shape)\n",
    "print('--------------')\n",
    "print(y_train.shape)\n",
    "print('--------------')\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d02fe210",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "#reshaping data for convolutional neural netowrks\n",
    "X_train = X_train.reshape(2250,32,32,3) \n",
    "y_train = y_train.reshape(2250,1)\n",
    "X_test = X_test.reshape(750,32,32,3)\n",
    "y_test = y_test.reshape(750,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb42cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data to float so we can divide by 255(UNICODE)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "962f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbd291b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=X_train.shape[1:])) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #getting max values from matrices\n",
    "model.add(Dropout(0.25)) #dropping weights\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #getting max values from matrices\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) #flattening data\n",
    "model.add(Dense(512)) # connecting neurons deeply\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94e7b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decay = regularization\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0d575eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 10s 129ms/step - loss: 1.0509 - accuracy: 0.4311 - val_loss: 0.9769 - val_accuracy: 0.5707\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 9s 120ms/step - loss: 0.9319 - accuracy: 0.5227 - val_loss: 0.9144 - val_accuracy: 0.5213\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 9s 128ms/step - loss: 0.8498 - accuracy: 0.5702 - val_loss: 0.7962 - val_accuracy: 0.5907\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 9s 122ms/step - loss: 0.7937 - accuracy: 0.5862 - val_loss: 0.8015 - val_accuracy: 0.5600\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 9s 128ms/step - loss: 0.7731 - accuracy: 0.6107 - val_loss: 0.7592 - val_accuracy: 0.6187\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 9s 130ms/step - loss: 0.7486 - accuracy: 0.6142 - val_loss: 0.8311 - val_accuracy: 0.5600\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 11s 149ms/step - loss: 0.7222 - accuracy: 0.6333 - val_loss: 0.7680 - val_accuracy: 0.6093\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 10s 144ms/step - loss: 0.7113 - accuracy: 0.6458 - val_loss: 0.7648 - val_accuracy: 0.6267\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 0.7098 - accuracy: 0.6369 - val_loss: 0.7325 - val_accuracy: 0.6413\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 0.7020 - accuracy: 0.6409 - val_loss: 0.7068 - val_accuracy: 0.6533\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 10s 140ms/step - loss: 0.6863 - accuracy: 0.6511 - val_loss: 0.7321 - val_accuracy: 0.6080\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.6732 - accuracy: 0.6756 - val_loss: 0.7205 - val_accuracy: 0.6400\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.6646 - accuracy: 0.6711 - val_loss: 0.6977 - val_accuracy: 0.6453\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 0.6494 - accuracy: 0.6778 - val_loss: 0.7713 - val_accuracy: 0.6280\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 0.6462 - accuracy: 0.6809 - val_loss: 0.6815 - val_accuracy: 0.6600\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.6405 - accuracy: 0.6871 - val_loss: 0.6729 - val_accuracy: 0.6787\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.6240 - accuracy: 0.6987 - val_loss: 0.6646 - val_accuracy: 0.6800\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 0.6295 - accuracy: 0.6889 - val_loss: 0.6598 - val_accuracy: 0.6773\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 13s 178ms/step - loss: 0.6047 - accuracy: 0.7102 - val_loss: 0.6789 - val_accuracy: 0.6787\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 0.6006 - accuracy: 0.7173 - val_loss: 0.6736 - val_accuracy: 0.6840\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 10s 140ms/step - loss: 0.6035 - accuracy: 0.7187 - val_loss: 0.7013 - val_accuracy: 0.6627\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.5932 - accuracy: 0.7231 - val_loss: 0.6717 - val_accuracy: 0.6867\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 11s 150ms/step - loss: 0.5937 - accuracy: 0.7262 - val_loss: 0.6773 - val_accuracy: 0.6787\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 10s 142ms/step - loss: 0.5795 - accuracy: 0.7258 - val_loss: 0.6750 - val_accuracy: 0.6520\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 10s 144ms/step - loss: 0.5746 - accuracy: 0.7262 - val_loss: 0.6666 - val_accuracy: 0.6813\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 10s 143ms/step - loss: 0.5721 - accuracy: 0.7236 - val_loss: 0.6390 - val_accuracy: 0.7013\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.5602 - accuracy: 0.7356 - val_loss: 0.6544 - val_accuracy: 0.6827\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.5552 - accuracy: 0.7373 - val_loss: 0.6572 - val_accuracy: 0.7027\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.5475 - accuracy: 0.7493 - val_loss: 0.8044 - val_accuracy: 0.6453\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 10s 143ms/step - loss: 0.5426 - accuracy: 0.7467 - val_loss: 0.6850 - val_accuracy: 0.6747\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 11s 156ms/step - loss: 0.5377 - accuracy: 0.7600 - val_loss: 0.6535 - val_accuracy: 0.6987\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.5280 - accuracy: 0.7551 - val_loss: 0.6527 - val_accuracy: 0.6893\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 9s 129ms/step - loss: 0.5305 - accuracy: 0.7542 - val_loss: 0.6388 - val_accuracy: 0.6973\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.5287 - accuracy: 0.7560 - val_loss: 0.7554 - val_accuracy: 0.6360\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 0.5233 - accuracy: 0.7658 - val_loss: 0.6656 - val_accuracy: 0.6827\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 9s 127ms/step - loss: 0.5105 - accuracy: 0.7676 - val_loss: 0.6574 - val_accuracy: 0.7000\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 9s 131ms/step - loss: 0.5079 - accuracy: 0.7764 - val_loss: 0.6316 - val_accuracy: 0.7067\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 10s 142ms/step - loss: 0.5075 - accuracy: 0.7680 - val_loss: 0.6256 - val_accuracy: 0.7160\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 10s 145ms/step - loss: 0.5008 - accuracy: 0.7831 - val_loss: 0.6498 - val_accuracy: 0.6880\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4930 - accuracy: 0.7849 - val_loss: 0.6179 - val_accuracy: 0.7053\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.4854 - accuracy: 0.7742 - val_loss: 0.6343 - val_accuracy: 0.7267\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.4753 - accuracy: 0.7844 - val_loss: 0.6805 - val_accuracy: 0.7013\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.4726 - accuracy: 0.7889 - val_loss: 0.6410 - val_accuracy: 0.7173\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4764 - accuracy: 0.7822 - val_loss: 0.6269 - val_accuracy: 0.7253\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.4637 - accuracy: 0.7862 - val_loss: 0.6769 - val_accuracy: 0.6987\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4594 - accuracy: 0.7902 - val_loss: 0.7102 - val_accuracy: 0.6853\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.4603 - accuracy: 0.7898 - val_loss: 0.7653 - val_accuracy: 0.6787\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 0.4460 - accuracy: 0.8009 - val_loss: 0.6385 - val_accuracy: 0.7080\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.4452 - accuracy: 0.8000 - val_loss: 0.6389 - val_accuracy: 0.7147\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4455 - accuracy: 0.7942 - val_loss: 0.6560 - val_accuracy: 0.6960\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.4279 - accuracy: 0.8076 - val_loss: 0.6351 - val_accuracy: 0.7107\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4235 - accuracy: 0.8040 - val_loss: 0.6583 - val_accuracy: 0.7107\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.4246 - accuracy: 0.8098 - val_loss: 0.7343 - val_accuracy: 0.6920\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4169 - accuracy: 0.8209 - val_loss: 0.6238 - val_accuracy: 0.7373\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.4081 - accuracy: 0.8147 - val_loss: 0.6296 - val_accuracy: 0.7320\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.4076 - accuracy: 0.8249 - val_loss: 0.6246 - val_accuracy: 0.7360\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.3992 - accuracy: 0.8298 - val_loss: 0.6321 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 0.3963 - accuracy: 0.8253 - val_loss: 0.6158 - val_accuracy: 0.7333\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 10s 141ms/step - loss: 0.3943 - accuracy: 0.8347 - val_loss: 0.7387 - val_accuracy: 0.7107\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 10s 145ms/step - loss: 0.3847 - accuracy: 0.8316 - val_loss: 0.7097 - val_accuracy: 0.7067\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 10s 144ms/step - loss: 0.3845 - accuracy: 0.8311 - val_loss: 0.6386 - val_accuracy: 0.7267\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 0.3767 - accuracy: 0.8440 - val_loss: 0.7179 - val_accuracy: 0.6827\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.3811 - accuracy: 0.8356 - val_loss: 0.6223 - val_accuracy: 0.7360\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 10s 136ms/step - loss: 0.3753 - accuracy: 0.8387 - val_loss: 0.6983 - val_accuracy: 0.7000\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.3632 - accuracy: 0.8458 - val_loss: 0.6306 - val_accuracy: 0.7240\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.3600 - accuracy: 0.8507 - val_loss: 0.6814 - val_accuracy: 0.7147\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 10s 138ms/step - loss: 0.3555 - accuracy: 0.8542 - val_loss: 0.6538 - val_accuracy: 0.7307\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 10s 139ms/step - loss: 0.3407 - accuracy: 0.8533 - val_loss: 0.7662 - val_accuracy: 0.7013\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 10s 142ms/step - loss: 0.3435 - accuracy: 0.8600 - val_loss: 0.6497 - val_accuracy: 0.7427\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 11s 156ms/step - loss: 0.3428 - accuracy: 0.8560 - val_loss: 0.7379 - val_accuracy: 0.7107\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 10s 144ms/step - loss: 0.3353 - accuracy: 0.8569 - val_loss: 0.7053 - val_accuracy: 0.7053\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 10s 141ms/step - loss: 0.3271 - accuracy: 0.8520 - val_loss: 0.7181 - val_accuracy: 0.7120\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 12s 167ms/step - loss: 0.3249 - accuracy: 0.8658 - val_loss: 0.6359 - val_accuracy: 0.7547\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 12s 169ms/step - loss: 0.3158 - accuracy: 0.8760 - val_loss: 0.6513 - val_accuracy: 0.7373\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 0.3277 - accuracy: 0.8618 - val_loss: 0.6918 - val_accuracy: 0.7280\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 10s 148ms/step - loss: 0.3161 - accuracy: 0.8649 - val_loss: 0.6918 - val_accuracy: 0.7187\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 10s 147ms/step - loss: 0.3008 - accuracy: 0.8760 - val_loss: 0.6783 - val_accuracy: 0.7280\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 0.2952 - accuracy: 0.8782 - val_loss: 0.6514 - val_accuracy: 0.7520\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 10s 147ms/step - loss: 0.2965 - accuracy: 0.8760 - val_loss: 0.6464 - val_accuracy: 0.7507\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 10s 142ms/step - loss: 0.3009 - accuracy: 0.8738 - val_loss: 0.7651 - val_accuracy: 0.7187\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 11s 150ms/step - loss: 0.2808 - accuracy: 0.8800 - val_loss: 0.7652 - val_accuracy: 0.7173\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 10s 145ms/step - loss: 0.2917 - accuracy: 0.8849 - val_loss: 0.6537 - val_accuracy: 0.7440\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 0.2762 - accuracy: 0.8902 - val_loss: 0.7660 - val_accuracy: 0.7200\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 10s 134ms/step - loss: 0.2752 - accuracy: 0.8916 - val_loss: 0.7421 - val_accuracy: 0.7293\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.2706 - accuracy: 0.8840 - val_loss: 0.6449 - val_accuracy: 0.7507\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 11s 149ms/step - loss: 0.2713 - accuracy: 0.8853 - val_loss: 0.6707 - val_accuracy: 0.7360\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.2586 - accuracy: 0.8956 - val_loss: 0.6900 - val_accuracy: 0.7253\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 9s 131ms/step - loss: 0.2658 - accuracy: 0.8987 - val_loss: 0.7366 - val_accuracy: 0.7187\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 9s 131ms/step - loss: 0.2456 - accuracy: 0.9040 - val_loss: 0.7384 - val_accuracy: 0.7333\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 0.2507 - accuracy: 0.8978 - val_loss: 0.8198 - val_accuracy: 0.7067\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 9s 132ms/step - loss: 0.2469 - accuracy: 0.8987 - val_loss: 0.7007 - val_accuracy: 0.7427\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 10s 144ms/step - loss: 0.2414 - accuracy: 0.9036 - val_loss: 0.6736 - val_accuracy: 0.7547\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 10s 145ms/step - loss: 0.2270 - accuracy: 0.9098 - val_loss: 0.6909 - val_accuracy: 0.7400\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.2308 - accuracy: 0.9133 - val_loss: 0.7464 - val_accuracy: 0.7147\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 10s 137ms/step - loss: 0.2235 - accuracy: 0.9151 - val_loss: 0.7020 - val_accuracy: 0.7480\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 10s 140ms/step - loss: 0.2351 - accuracy: 0.9009 - val_loss: 0.7848 - val_accuracy: 0.7360\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.2179 - accuracy: 0.9107 - val_loss: 0.7571 - val_accuracy: 0.7453\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.2316 - accuracy: 0.9071 - val_loss: 0.6951 - val_accuracy: 0.7520\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 9s 133ms/step - loss: 0.2121 - accuracy: 0.9111 - val_loss: 0.7814 - val_accuracy: 0.7320\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 10s 135ms/step - loss: 0.2123 - accuracy: 0.9156 - val_loss: 0.7708 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6cff9af70>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(X_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1497eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 25ms/step - loss: 0.7708 - accuracy: 0.7333\n",
      "Test loss: 0.7708353400230408\n",
      "Test accuracy: 0.7333333492279053\n"
     ]
    }
   ],
   "source": [
    "#evaluating \n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcf359ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5634dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions 1D for accuracy and report\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "880ed07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making testing labels 1D for accuracy and report\n",
    "y_test = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e53848a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "accuracy = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3dd66a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a53e031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2fb85bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.61       262\n",
      "           1       0.59      0.83      0.69       249\n",
      "           2       0.94      0.88      0.91       239\n",
      "\n",
      "    accuracy                           0.73       750\n",
      "   macro avg       0.76      0.74      0.74       750\n",
      "weighted avg       0.76      0.73      0.73       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b788b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df268b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
